* * *

# Custom Churn Prediction Project
===============================

This repository contains a comprehensive project for churn prediction, utilizing four unique datasets and implementing four advanced machine learning models. The aim is to identify the most effective model and dataset combination for predicting customer churn.

# Project Overview
----------------

Churn prediction is critical for businesses to retain customers and enhance loyalty. This project explores various datasets and algorithms to achieve high-accuracy predictions and insightful visualizations.

### Datasets

1.  **Telco-Customer-Churn**  
    A detailed dataset of customer information and churn status from a telecommunications company.
2.  **customer\_churn\_dataset-testing-master**  
    A diverse dataset for testing churn prediction models.
3.  **Churn\_Modelling**  
    A widely-used dataset with customer demographics and churn indicators.
4.  **cell2cellholdout**  
    Focused on churn behaviors in the telecommunications sector.

### Algorithms Used

Each dataset was trained on the following machine learning models:

*   **XGBoost**: Known for its speed and performance in structured data.
*   **Random Forest**: A robust ensemble method providing high accuracy.
*   **Support Vector Machine (SVM)**: Effective in handling high-dimensional spaces.
*   **Stacking**: Combines multiple models to improve performance.

# Key Features
------------

*   **Data Visualization**: Comprehensive visual insights into each dataset's features, distributions, and patterns.
*   **Model Comparison**: Metrics such as accuracy, precision, recall, and F1-score to evaluate performance.
*   **Code Modularity**: Clean, reusable, and well-documented code for scalability and reproducibility.

# Installation
------------

1.  Clone the repository:
    
    ```bash
    git clone https://github.com/zyad-ashraf-amar/Custom-Churn.git
    ```
    
2.  Navigate to the project directory:
    
    ```bash
    cd Custom-Churn-Prediction
    ```

How to Use
----------

1.  Open the notebooks under the `notebooks` folder to explore the analysis and results.
2.  Run the scripts to train and evaluate the models on the datasets.
3.  Visualizations can be found in the `visualizations` folder for reference.

Author
------

**Zyad Ashraf**  
Junior ML Engineer passionate about predictive analytics and machine learning.

* * *
